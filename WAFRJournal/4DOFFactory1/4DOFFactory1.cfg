# General-purpose settings.
#color = false
verbose = true

[problem]
logPath = log
logFilePostfix = 
policyPath = final-ABT-policy.pol

#planningEnvironmentPath = 4DOFEmptyEnvironment.sdf
#executionEnvironmentPath = 4DOFEmptyEnvironment.sdf
planningEnvironmentPath = 4DOFFactory1.sdf
executionEnvironmentPath = 4DOFFactory1.sdf

robotPath = 4DOFManipulator.sdf
robotConfigPath = 4DOFFactory1Config.yaml
#goalStatesPath = goalstates_kuka.txt
goalStatesPath = 

enableGazeboStateLogging = true
overwriteExistingLogFiles = false

solverPlugin = libabt_plugin.so
executionPlugin = libexec_plugin.so

#################################################
## Uncertainty parameters
#################################################
minProcessCovariance = 0.005
maxProcessCovariance = 1000.0

minObservationCovariance = 0.005
maxObservationCovariance = 1000.0

incCovariance = observation
covarianceSteps = 1

discountFactor = 0.99

# discrete or continuous
actionType = discrete

# Using state- action- and observation spaces that are normalized to [0, 1]
normalizedSpaces = true

exitReward = 1000.0
illegalMovePenalty = 500.0
illegalActionPenalty = 500.0
stepPenalty = 1.0
numInputSteps = 2

# The initial state of the robot. Has to be consistent with the number of degrees of freedom
#initState = [0.0, 0.0, 0.0, 0.0]
initState = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

# linear or nonlinear
observationType = nonlinear

allowCollisions = false

[DYNAMICS]
controlDuration = 0.1
#epsProcess = 0.05
epsProcess = 0.001
epsObservation = 0.000001
lazyCollisionCheck = false

[RRT]
rrtVerbose = false
planner = RRTConnect

# For ABT
planningRange = 0.06

# For SNM-Planner
#planningRange = 0.06
continuousCollision = false
continuousCollisionDynamic = true
rrtGoalBias = 0.0175

# RRT timeout in milliseconds
rrtTimeout = 1000.0
numControlSamples = 1

[HFR]
controlSampler = discrete
dynamicPlanner = RRT
pathDeviationCost = 1000
controlDeviationCost = 1000
numEvaluationSamples = 200
minMaxControlDuration = [1, 5]
numThreads = 7

[MON]
Threshold for SNM
monThreshold = 0.6

Threshold for NonGaussian
#monThreshold = 1.8

Threshold for Curvature
#monThreshold = 0.0

# Minimum number of sampled actions (0 => wait for timeout)
numSampledActions = 0

# The number os states that are sampled from the current belief for a sampled action
numSampledStates = 1

# The number of error that a sampled for each state-action pair
numSampledErrors = 75
numSampledErrorsObservation = 0

# Number of sampled states for the observation MoN
numSampledStatesObservation = 0

#Timeout to calculate the MoN in milliseconds
monTimeout = 400
numBins = 2
numMonThreads = 14
actionSamplingStrategy = ucb

#The number of action samples after which the action distribution should be updated
sampleBatchSize = 10

# The number of sampled directions for the curvature-based measure
numSampledDirections = 1

[RANDOMSCENE]
randomScene = false
numRandomObstacles = 30
randomObstacleDimensions = [0.5, 0.5, 0.5]
intervalX = [-4.0, 4.0]
intervalY = [-4.0, 4.0]
intervalZ = [-3.0, 3.0]

[changes]
hasChanges = false
changesPath = changes/manipulator-changes.txt
areDynamic = true

[ABT]
# The number of trajectories to simulate per time step (0 => wait for timeout)
historiesPerStep = 0

# The maximum time to spend on each step, in milliseconds (0 => no time limit)
stepTimeout = 2000

# If this is set to "true", ABT will prune the tree after every step.
pruneEveryStep = true

# If this is set to "true", ABT will reset the tree instead of modifying it when
# changes occur.
resetOnChanges = false

# The particle filter to use
particleFilter = observationModel

# The minimum number of particles for the current belief state in a simulation.
# Extra particles will be resampled via a particle filter if the particle count
# for the *current* belief state drops below this number during simulation.
minParticleCount = 3000

# Minimum number of effective particles below which resampling is happening
numEffectiveParticles = 10001

# Maximum number of particles to plot
particlePlotLimit = 100

# Maximum time (in milliseconds) to replenish the particles
particleReplenishTimeout = 10000.0

# The maximum depth to search in the tree, relative to the current belief.
maximumDepth = 1000

maxObservationDistance = 1.0
#maxObservationDistance = 9000.0

# True if the above horizon is relative to the initial belief, and false
# if it's relative to the current belief.
isAbsoluteHorizon = false

searchHeuristic = default()
searchStrategy = ucb(2.0)

# explorationFactor, minNumSamples, maxDistanceToMean, maxCovariance
#searchStrategy = approx(2.0, 5, 0.075, 0.005)
estimator = max()

##### For continuous actions ######
#searchStrategy = gps2(searchType=compass, dimensions=0, explorationCoefficient=10, newSearchPointCoefficient=5, minimumVisitsBeforeChildCreation=1, minimumChildCreationDistance=0.2, #initialCompassRadiusRatio=1.0)
#recommendationStrategy = gps2max(searchType=compass, dimensions=0, recommendationMode=mean)

stateSamplingStrategy = default

numSamplesWeightedLazy = 10

# 'simple', 'distance' or 'dynamic'
heuristicFunction = simple
heuristicTimeout = 0.1

[simulation]
loadInitialPolicy = false
savePolicy = false
saveParticles = false
nRuns = 1
nSteps = 35
showViewer = false
